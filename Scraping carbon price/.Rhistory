import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
import lxml
driver = webdriver.Firefox()
driver.get("https://www.chinatcx.com.cn/list/13.html?page=1")
all_tables = []
i=0
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables))
import lxml
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables))
dfs = pd.read_html(str(tables), flavor='html5lib`)
dfs = pd.read_html(str(tables), flavor='html.parser`)
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
all_tables.append(dfs)
dfs[0]
all_tables.append(dfs)
all_tables = []
for i in range(41):
driver.get("https://www.chinatcx.com.cn/list/13.html?page={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
all_tables[40][0]
i=41
driver.get("https://www.chinatcx.com.cn/list/13.html?page={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
all_tables[41][0]
all_tables[0]
columnames(all_tables.append)
all_tables.columns.values
all_tables[0].columns.values
all_tables[[0]].columns.values
all_tables[[0]].columns.values.tolist()
all_tables[0].columns.values.tolist()
df_tables = pd.DataFrame()
for j in range(41):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
df_tables = pd.concat([df_tables, all_tables[41][0]], axis=0).reset_index(drop=True)
df_tables.to_excel("TJ_20230130_20131226_Carbon.xlsx")
df_tables.to_excel("TJ_20230130_20131226_Carbon.xlsx")
driver.get("https://www.chinatcx.com.cn/list/123.html")
print("https://www.chinatcx.com.cn/list/123.html?page={}".format(i+1))
all_tables = []
for i in range(19):
driver.get("https://www.chinatcx.com.cn/list/123.html?page={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
df_tables = pd.DataFrame()
for j in range(19):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
View(df_tables)
df_tables.to_excel("ALL_20230131_20210716_Carbon.xlsx")
driver.get("https://szets.com/dailynewsCN/index.htm")
all_tables = []
for i in range(476):
driver.get("https://szets.com/dailynewsCN/index_{}.htm".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
df_tables = pd.DataFrame()
for j in range(476):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
View(df_tables)
driver.get("https://tpf.cqggzy.com/itf/themes/cqkfts/index.html")
all_tables = []
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
View(dfs)
all_tables.append(dfs)
View(all_tables)
pd.DataFrame(all_tables)
pd.DataFrame(all_tables[0])
pd.DataFrame(all_tables[0])
pd.DataFrame(all_tables[1])
all_tables[1]
all_tables[0]
all_tables[0]
pd.DataFrame(all_tables[0])
df_tables = pd.DataFrame(all_tables)
df_tables = pd.DataFrame(all_tables[0])
all_tables[0]
type(all_tables[0])
df_tables = pd.DataFrame(all_tables[0])
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
View(df_tables)
# Get dataframe
df_tables = pd.DataFrame()
for j in range(2):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
for j in range(1=):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
j=1
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
all_tables[1]
all_tables[0]
df_tables = pd.DataFrame()
for j in range(0):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
all_tables[0]
all_tables[0][0]
all_tables[0][1]
# Get dataframe
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=0).reset_index(drop=True)
View(df_tables)
# Get dataframe
df_tables = pd.DataFrame()
for j in range(2):
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=0).reset_index(drop=True)
View(df_tables)
all_tables[0][1]
df_tables = pd.DataFrame()
for j in range(2):
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=1).reset_index(drop=True)
View(df_tables)
View(df_tables)
all_tables[0][0]
all_tables[1][0]
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=0).reset_index(drop=True)
j=1
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=0).reset_index(drop=True)
View(df_tables)
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=1).reset_index(drop=True)
j=1
df_tables = pd.concat([df_tables, all_tables[0][j]], axis=1).reset_index(drop=True)
View(df_tables)
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.merge([df_tables, all_tables[0][j]], axis=1).reset_index(drop=True)
df_tables = pd.DataFrame()
for j in range(1):
df_tables = pd.merge([df_tables, all_tables[0][j]]).reset_index(drop=True)
df_tables = pd.merge([df_tables, all_tables[0][j]], how = 'inner').reset_index(drop=True)
View(all_tables)
[all_tables]
type([all_tables])
type([[all_tables]])
all_tables
View(all_tables)
[all_tables]
pd.DataFrame([all_tables])
View(all_tables)
[all_tables[0]]
type([all_tables[0]])
pd.DataFrame([all_tables[0]])
[all_tables[0]]
type([all_tables[0]])
[[all_tables[0]]]
all_tables[0][1]
type(all_tables[0][1])
all_tables[0][0]
all_tables[0][1].columns = all_tables[0][0]
all_tables[0][0].columns
all_tables[0][1].columns = all_tables[0][0].columns
all_tables[0][1].
all_tables[
all_tables
s
all_tables
all_tables[0][1]
all_tables[0][1].to_excel("CQ_20230131_20140619_Carbon.xlsx")
driver = webdriver.Firefox()
driver.get("https://szets.com/dailynewsCN/index.htm")
all_tables = []
for i in range(476):
driver.get("https://szets.com/dailynewsCN/index_{}.htm".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
df_tables = pd.DataFrame()
for j in range(476):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
df_tables.to_excel("SZ_20230131_20150518_Carbon.xlsx")
driver.get("https://ets.sceex.com.cn/?language=zh_CN")
all_tables = []
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
`
all_tables = []
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
View(all_tables)
View(all_tables)
all_tables[0][1]
View(all_tables)
all_tables[0][3]
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex=1")
all_tables = []
for i in range(98):
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex=".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
all_tables = []
for i in range(98):
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
driver = webdriver.Firefox()
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex=1")
all_tables = []
for i in range(98):
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
df_tables = pd.DataFrame()
for j in range(98):
df_tables = pd.concat([df_tables, all_tables[j][0]], axis=0).reset_index(drop=True)
View(df_tables)
View(df_tables)
df_tables.to_excel("SC_20230131_20161216_Carbon.xlsx")
driver.get("https://www.cneeex.com/cneeex/daytrade/detail?SiteID=122#;")
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
# Get all tables
all_tables = []
for i in range(98):
driver.get("https://ets.sceex.com.cn/history.htm?k=li_shi_xing_qing&url=mrhq_ls&pageIndex={}".format(i+1))
driver.implicitly_wait(10)
soup = BeautifulSoup(driver.page_source, 'html.parser')
tables = soup.find_all('table')
dfs = pd.read_html(str(tables), flavor='html5lib')
all_tables.append(dfs)
driver = webdriver.Firefox()
driver.get("https://www.cneeex.com/cneeex/daytrade/detail?SiteID=122#;")
reticulate::repl_python()
action.move_to_element_with_offset(element, 280, 0).perform()
reticulate::repl_python()
action.move_to_element_with_offset(element, 280, 0)
action.move_to_element_with_offset(element, 280, 0).perform()
action.move_to_element_with_offset(element, 0, 0)
reticulate::repl_python()
action = ActionChains(driver)
reticulate::repl_python()
action = ActionChains(driver)
action = webdriver.ActionChains(driver)
action = webdriver.ActionChains()
reticulate::repl_python()
action = webdriver.ActionChains(driver)
reticulate::repl_python()
action = webdriver.ActionChains(driver)
action = webdriver.ActionChains(driver)
library("readxl")
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
View(HB)
library(tidyverse)
HB %>% colnames()
colnames(HB)
colnames(HB) = c['Date', 'Value]
HB
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c['Date', 'Value']
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB
HB$Value = gsub('元','吨',HB$Value)
HB
HB$Value = gsub('元','',HB$Value)
HB$Value = gsub('元','',HB$Value)
HB
HB$Value = gsub('吨','',HB$Value)
HB
gsub(c('成交量', '成交价'),'',HB$Value)
HB$Value = gsub('成交量','',HB$Value)
HB$Value = gsub('成交价','',HB$Value)
HB
HB$Value = gsub('\r\n湖北 : ','',HB$Value)
HB
gsub('substring(HB$Value, 10)','',HB$Value)
gsub(substring(HB$Value, 10),'',HB$Value)
substring(HB$Value, 10)
substring(HB$Value, 11)
substring(HB$Value, 11)
HB$Value = substring(HB$Value, 11)
HB
str_split_fixed(HB$Value, ':', 2)
HB$Value = str_split_fixed(HB$Value, ':', 2)
HB
HB
HB$Value
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB$Value = gsub('元','',HB$Value)
HB$Value = gsub('吨','',HB$Value)
HB$Value = gsub('成交量','',HB$Value)
HB$Value = gsub('成交价','',HB$Value)
HB$Value = gsub('\r\n湖北 : ','',HB$Value)
HB$Value = substring(HB$Value, 11)
HB
str_split_fixed(HB$Value, ':', 2) %>% as.tibble()
HB = str_split_fixed(HB$Value, ':', 2) %>% as.tibble()
HB
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB$Value = gsub('元','',HB$Value)
HB$Value = gsub('吨','',HB$Value)
HB$Value = gsub('成交量','',HB$Value)
HB$Value = gsub('成交价','',HB$Value)
HB$Value = gsub('\r\n湖北 : ','',HB$Value)
HB$Value = substring(HB$Value, 11)
HB
new_HB = str_split_fixed(HB$Value, ':', 2) %>% as.tibble()
new_HB
HB <- read_excel("/Users/tonygong/Downloads/HB.xlsx")
colnames(HB) = c('Date', 'Value')
HB$Value = gsub('元','',HB$Value)
HB$Value = gsub('吨','',HB$Value)
HB$Value = gsub('成交量','',HB$Value)
HB$Value = gsub('成交价','',HB$Value)
HB$Value = gsub('\r\n湖北 : ','',HB$Value)
HB$Value = substring(HB$Value, 11)
new_HB = str_split_fixed(HB$Value, ':', 2) %>% as.tibble()
new_HB
HB
new_HB['Date']= HB$Date
new_HB
new_HB[,c(3,1,2)]
new_HB = new_HB[,c(3,1,2)]
colnames(new_HB) = c("Date", "Price", "Volume")
new_HB
library("writexl")
install.packages("writexl")
write_xlsx(new_HB,"/Users/tonygong/Downloads/new_HB.xlsx")
write_xlsx(new_HB,"/Users/tonygong/Downloads/new_HB.xlsx")
library(writexl)
write_xlsx(new_HB,"/Users/tonygong/Downloads/new_HB.xlsx")
